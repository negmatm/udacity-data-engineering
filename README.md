# Data Modeling with Postgres

## About

This project contains scripts for creating a dimensional model (Fact and Dimension tables), reading and loading data files into this data model.  It also contains raw data files.

## Data
* **Song Dataset**
This dataset is a subset of real data from the Million Song Dataset. Each file is in JSON format and contains metadata about a song and the artist of that song. The files are partitioned by the first three letters of each song's track ID.
Sample file path: song_data/A/B/C/TRABCEI128F424C983.json

* **Log Dataset**
This dataset consists of log files in JSON format generated by this event simulator based on the songs in the dataset above. These simulate activity logs from a music streaming app based on specified configurations.
Sample file path:log_data/2018/11/2018-11-12-events.json

## Scripts
* **sql_queries.py:** Defines all the needed SQL queries
* **create_tables.py:** Contains the code to create the database and run queries within sql_queries.py to create needed fact/dimension tables
* **etl.py:** Main ETL program, which processes log files, and loads the data into fact/dimension tables

## Processing
1. Run **create_tables.py** to create the database and dimension/fact tables
2. Run **etl.py** to read the files and load them into the database tables
